@misc{roy_leakage_2022,
	title = {Leakage {Certification} based on {Consistent} {MI} {Estimation}},
	url = {https://eprint.iacr.org/2022/1201},
	abstract = {The mutual information between two variables is a key metric in the context of side-channel attacks; in particular, it is used to judge the quality of device leakage models. In practice the mutual information can only be estimated, and existing methods in the side channel community are based on density estimation. Estimating the mutual information based on estimating distribution densities is a challenge unless assumptions about the underlying distributions can be made --- this is undesirable in the side channel setting because the underlying distributions are unknown. We suggest a radically different approach to the mutual information estimation in the side channel setting based on a recently proposed \$k\$-Nearest Neighbour estimator. We prove that the mutual information between the key and the observed side channel can be efficiently estimated without the need for any density estimation, even in multivariate settings, and we mathematically characterise the impact of some assumptions/restrictions of previous work on the estimation process. To complement our theoretical results, we offer a wide range of experimental results that compare our proposal with the state-of-the-art estimators used in the side channel community. Finally, we show in experiments the advantages of our proposed method for judging the quality of leakage models, in comparison to the existing techniques.},
	urldate = {2023-05-02},
	author = {Roy, Arnab and Chowdhury, Aakash and Oswald, Elisabeth},
	year = {2022},
	keywords = {Leakage Certification, Mutual Information},
}
@misc{gkov,
  doi = {10.48550/ARXIV.1709.06212},
  url = {https://arxiv.org/abs/1709.06212},
  author = {Gao,  Weihao and Kannan,  Sreeram and Oh,  Sewoong and Viswanath,  Pramod},
  keywords = {Information Theory (cs.IT),  Machine Learning (cs.LG),  FOS: Computer and information sciences,  FOS: Computer and information sciences},
  title = {Estimating Mutual Information for Discrete-Continuous Mixtures},
  publisher = {arXiv},
  year = {2017},
  copyright = {arXiv.org perpetual,  non-exclusive license}
}
@book{gsl,
	address = {Bristol},
	edition = {3. ed},
	title = {{GNU} scientific library reference manual: for {GSL} version 1.12},
	isbn = {9780954612078},
	shorttitle = {{GNU} scientific library reference manual},
	language = {eng},
	publisher = {Network Theory},
	editor = {Galassi, Mark},
	year = {2009},
}